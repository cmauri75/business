cor(head(compareTable[1:10,1],compareTable[1:10,2])
cor(compareTable[1:10,1],compareTable[1:10,2])
compareTable[1:10,2]
compareTable[1:10,1]
cor(compareTable[,1],compareTable[,2])
cor(head(compareTable[,1],10),head(compareTable[,2],10)
cor(head(compareTable[,1],10),head(compareTable[,2],10))
head(compareTable[,1],10)
head(compareTable[,1],10)
compareTable[,1]
compareTable[,2]
compareTable[,1]
compareTable[,1]
r1 <- compareTable[,1]
r2 <- compareTable[,2]
cor(r1,r2)
r1 <- head(compareTable[,1],10)
r2 <- head(compareTable[,2],10)
cor(r1,r2)
cor(head(compareTable[,1],10),head(compareTable[,1],10))
cor(head(compareTable[,1],10),head(compareTable[,2],10))
cor(head(compareTable[,1],10),head(compareTable[,2],10))
cor(head(compareTable[,1],20),head(compareTable[,2],20))
summary(linreg)
plot(data$Balance,data$Rating)
plot(data$Income,data$Rating)
plot(data$Student,data$Rating)
hist(data$student)
hist(data$Student)
plot(data$Rating,data$Student)
rm(list=ls(all=TRUE))
datatot=read.table('DATA_3.02_HR2.csv', header = T,sep=',')
str(datatot) # The str() function shows the structure of your dataset and details the type of variables that it contains
view(datatot) # The str() function shows the structure of your dataset and details the type of variables that it contains
view(datatot)
View(datatot)
summary(datatot)
table(datatot$left)
table(datatot$left)/nrow(datatot) # look at percentages for the left variable
table(datatot$left)/nrow(datatot)
hist(datatot$left)
cor(datatot)
rm(list=ls(all=TRUE))
#income in kdollari, rating (score, la variabile indipendente da predirre), numero cc, età, #anni di studio, gender, studente?, sposato?, etnia, debito medio sulla carta
data=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE)
View(data)
summary(data)
#creo un istogramma per vedere come sono distribuiti i vari dati
hist(data$Rating)
hist(data$Balance)
hist(data$Income)
tapply(data$Income,data$Ethnicity,mean) #gli africani guadagnano di più
#qui cerco la correlazione tra tutti i dati numerici nella tabella, escludo quindi quelli anagrafici discreti
##trovo delle relazioni tra le varie colonne, ma non mi serve molto (non ho capito come mai)
cor(data[,c(1:5,10)])
rm(list=ls(all=TRUE))
datatot=read.table('DATA_3.02_HR2.csv', header = T,sep=',')
summary(datatot)
#controllo come stanno i dati dell'abbandono
table(datatot$left)
table(datatot$left)/nrow(datatot)
hist(datatot$left)
#calcolo le correlazioni tra tutte le variabili
cor(datatot)
?logreg
??logreg
?glm
logreg = glm(left ~ ., family=binomial(logit), data=datatot) # Estimate the drivers of attrition
summary(logreg)
hist(logreg$fitted.values) # See the proportion of employee attrition according to the model
hist(datatot$left)
hist(logreg$fitted.values)
plot (logreg$fitted.values,datatot$left)
plot (datatot$left,logreg$fitted.values)
cor(logreg$fitted.values,datatot$left)
hist(logreg$fitted.values)
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0) # Compute the percentage of correctly classified employees who stayed
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
cutoff=.5
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
mean((logreg$fitted.values>cutoff)==(datatot$left==1)) # Compute the overall percentage of correctly classified employees
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.3
#calcolo le percentuali
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.3
#calcolo le percentuali
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.2
#calcolo le percentuali
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.9
#calcolo le percentuali
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
cutoff=.1
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.2
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.3
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.35
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
cutoff=.25
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
summary(logreg) # Report the results of the logistic regression
plot(datatot$TIC,datatot$left,main= "Time and Employee Attrition", ylab="Attrition", xlab= "Time spent")
co = (0:1,step=0.1)
co = (0:1,0.1)
seq (0:1,0.1)
seq (0:1,by = 0.1)
seq (from=0, to=1,by = 0.1)
seq (from=0, to=1,by = 0.05)
co = seq (from=0, to=1,by = 0.05)
mns = mean((logreg$fitted.values>cutoff)==(datatot$left==1))
logreg$fitted.values>cutoff)==(datatot$left==1)
logreg$fitted.values>cutoff)==(datatot$left==1
(logreg$fitted.values>cutoff)==(datatot$left==1)
mns = mean((logreg$fitted.values>co)==(datatot$left==1))
mns = mean((logreg$fitted.values>co)==(datatot$left==1)
)
(logreg$fitted.values>co)==(datatot$left==1)
(logreg$fitted.values>co[1])==(datatot$left==1)
mean((logreg$fitted.values>co[1])==(datatot$left==1))
mean((logreg$fitted.values>co[2])==(datatot$left==1))
mean((logreg$fitted.values>co[3])==(datatot$left==1))
mean((logreg$fitted.values>co[4])==(datatot$left==1))
for (c in co) c
for (v in co) v
for (v in seq(0,1, by 0.05)) v
for (v in seq(0,1, by 0.05))v
for (v in seq(0,1, by 0.05))
for (v in seq(0,1, by 0.05))
seq(0,1, by 0.05)
seq(0,1, by=0.05)
for (v in seq(0,1, by=0.05)) v
for (v in seq(0,1, by=0.05)) mean(c)
for (v in seq(0,1, by=0.05)) mean(v)
for (v in seq(0,1, by=0.05)) {c}
for (v in seq(0,1, by=0.05)) {v}
for (v in seq(0,1, by=0.05)) {cat(v)}
res = matrix(ncol = 2)
res = matrix(ncol = 2)
for (v in seq(0,1, by=0.05)){
res <- rbind(res,mean((logreg$fitted.values>v)==(datatot$left==1)))
}
View(res)
res = matrix(ncol = 2)
for (v in seq(0,1, by=0.05)){
res <- rbind(res,c(v,mean((logreg$fitted.values>v)==(datatot$left==1))))
}
View(res)
res = matrix(ncol = 2)
for (v in seq(0,1, by=0.005)){
))
res = matrix(ncol = 3)
for (v in seq(0,1, by=0.005)){
res <- rbind(res,c(v,
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0),
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
))
}
res = matrix(ncol = 3)
res <- rbind(res,c(v,
for (v in seq(0,1, by=0.005)){
sum((logreg$fitted.values<=v)&(datatot$left==0))/sum(datatot$left==0),
sum((logreg$fitted.values>v)&(datatot$left==1))/sum(datatot$left==1)
))
}
res = matrix(ncol = 3)
for (v in seq(0,1, by=0.005)){
res <- rbind(res,c(v,
sum((logreg$fitted.values<=v)&(datatot$left==0))/sum(datatot$left==0),
sum((logreg$fitted.values>v)&(datatot$left==1))/sum(datatot$left==1)
))
}
plot(res)
plot(res[1],res[2])
plot(res[,1],res[,2])
plot(res[,1],res[,3])
plot(res[,2],res[,3])
plot(res[,1],res[,2],res[,3])
plot(res[,1],res[,3])
summary(logreg)
plot(datatot$TIC,datatot$left,main= "Time and Employee Attrition", ylab="Attrition", xlab= "Time spent")
aggbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=mean)
tempdata=datatot
aggbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=mean)
View(aggbTimeRank)
plot(aggbTimeRank$TIC,aggbTimeRank$left,main= "Time and Employee Attrition", ylab="Average Attrition Rate", xlab= "Time spent")
plot(aggbTimeRank$TIC,aggbTimeRank$left,main= "Abbandono", ylab="Media abbandoni", xlab= "Tempo in azienda")
cntbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=length)
View(cntbTimeRank)
View(aggbTimeRank)
symbols(aggbTimeRank$TIC,aggbTimeRank$left,circles=cntbTimeRank$left, inches=.75, fg="white", bg="red",main= "Time and Employee Attrition", ylab="Average Attrition Rate", xlab= "Time spent")
tempdata=datatot
tempdata=datatot
rank(-tempdata$S)
round(rank(-tempdata$S)/600)
?rank
(r1 <- rank(x1 <- c(3, 1, 4, 15, 92)))
x2 <- c(3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5)
names(x2) <- letters[1:11]
(r2 <- rank(x2)) # ties are averaged
tempdata$rankSatis = round(rank(-tempdata$S)/600)
aggbSatisRank = aggregate(left~ rankSatis, data=tempdata, FUN=mean)
cntbSatisRank = aggregate(left~ rankSatis, data=tempdata, FUN=length)
symbols(aggbSatisRank$rankSatis,aggbSatisRank$left,circles=cntbSatisRank$left, inches=.2, fg="white", bg="red",main= "Satisfaction and Employee Attrition", ylab="Average Attrition Rate", xlab= "Rank of Satisfaction")
rm(list=ls(all=TRUE))
#income in kdollari, rating (score, la variabile indipendente da predirre), numero cc, età, #anni di studio, gender, studente?, sposato?, etnia, debito medio sulla carta
data=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE)
View(data)
summary(data)
#creo un istogramma per vedere come sono distribuiti i vari dati
hist(data$Rating)
hist(data$Balance)
hist(data$Income)
tapply(data$Income,data$Ethnicity,mean) #gli africani guadagnano di più
#qui cerco la correlazione tra tutti i dati numerici nella tabella, escludo quindi quelli anagrafici discreti
##trovo delle relazioni tra le varie colonne, ma non mi serve molto (non ho capito bene come mai, in effetti la correlazione tra rating e income/balancing è alta come poi capirò alla fine)
# la corr mi da indicazioni solo sulla forza e la direzione della correlazione
cor(data[,c(1:5,10)])
#creo un modello di regressione lineare tra la mia variabile cercata (Rating) e tutte le altre (.=*, se volevo indagarne una sola la specificavo, se più di una le unico con +)
linreg=lm(Rating~.,data=data)
#dal modello posso ottenere la previsione dei rate, li intabello per dare un'idea dell'accuratezza
compareTable <- matrix(ncol=2, nrow = 300, dimnames = list(c(1:300),c("Rate","CRate")))
compareTable[,1] <- data$Rating
compareTable[,2] <- linreg$fitted.values
#se la plotto ho la perfezione se ho una retta di 45°
plot(compareTable)
#controllo che vi sia buona correlazione, ce l'ho, però questa ha dei limiti (con molti numeri riesco sempre a trovare un buon algoritmo che fitta)
cor(linreg$fitted.values,data$Rating)
#graficamente vedo che per numeri bassi non fitta bene
#infatti:
compareTable <- compareTable[ order(compareTable[,1]), ]
cor(head(compareTable[,1],10),head(compareTable[,2],10))
#controllo i dettagli del mio modello
summary(linreg)
#Ora posso presentare le relazioni scoperte, nelle prime due si vede bene una correlazione lineare, la terza bo
plot(data$Income,data$Rating)
plot(data$Student,data$Rating)
plot(data$Balance,data$Rating)
cor(head(compareTable[,1],10),head(compareTable[,2],10))
plot(compareTable)
summary(linreg)
cor(linreg$fitted.values,data$Rating)
cor(data[,c(1:5,10)])
cor(data
)
cor(data[,])
cor(data[,c(1:10)])
View(data)
cor(data[,2],data[,6])
cor(data[,2],data[,2])
cor(data[,2],data[,3])
cor(data[,2],data[,6]=='Male'?0:1)
cor(data[,2],data[,6]=='Male'?0:1)
data[,6]=='Male'?0:1
data[,6]==='Male'?0:1
cor(data[,2],length(data[,6])
)
length(data[,6])
summary(linreg)
as.numeric(data[,6])
cor(data[,2],as.numeric(length(data[,6]))
)
as.numeric(length(data[,6])
)
as.numeric(length(data[,6]))
as.numeric(data[,6])
cor(data[,2],as.numeric(data[,6]))
View(data)
mean(data$Rating)
mean(data[data$Student]$Rating)
mean(data[data$Student=='Yes']$Rating)
mean(data[,data$Student=='Yes']$Rating)
data[,data$Student=='Yes']
data[,Student=='Yes']
data[,Student==='Yes']
data[,"Student"==='Yes']
data["Student"=='Yes']
data["Student"=='Yes',]
data[,"Student"=='Yes']
data["Student"=='Yes']
data[Student=='Yes']
data["Student"="Yes",]
data[Student=='Yes']
data[Student='Yes']
data[data["Student"]=='Yes']
data[data["Student"]=='Yes',]
data[data["Student"]=='Yes',2]
mean(data[data["Student"]=='Yes',2])
mean(data[data["Student"]=='No',2])
mean(data[data["Gender"]=='Male',2])
mean(data[data["Gender"]=='Female',2])
mean(data[data["Gender"]=='Male',2])
data[data["Gender"]=='Male',2]
data[data["Gender"]=='Male'
data[data["Gender"]=='Male'
data[data["Gender"]=='Male']
data[data[6]=='Male']
data[data[6]=='ale']
data[data[6]=='Female']
data[data[6]=='Female',]
data[data[6]=='Female',2]
data[data[6]=='Male',2]
data[data[6]=='Male',6]
data[data[6]=='Female',6]
data[data[6]=='Male',6]
data[
]
data[,6]
data[data[6]=='Male',6]
data[data[6]='Male',6]
data[data[6]=='Male',6]
mean(data[data["Gender"]=='Female',2])
mean(data[,2])
mean(data[data["Student"]=='No',2])
mean(data[data["Student"]=='Yes',2])
cor(data[,c(1:5,10)])
summary(linreg)
linregSmall=lm(Rating~Income+Cards+Married,data=data)
summary(linregSmall)
rm(list=ls(all=TRUE))
datatot=read.table('DATA_3.02_HR2.csv', header = T,sep=',')
summary(datatot)
#controllo come stanno i dati dell'abbandono
table(datatot$left)
table(datatot$left)/nrow(datatot)
hist(datatot$left)
#calcolo le correlazioni tra tutte le variabili per iniziare a darmi un'idea
#la soddisfazione è correlata negativamente, il numero di progetti leggermente positivo e il newborn un po' positivo
#le correlazioni però sono analizzate in modo separato, senza capire come interagiscono tra di loro. (in verità il numero di progetti aiuta a non far lasciare)
cor(datatot)
#qui uso un modello di regressione logica, ottengo una probabilità di abbandono
logreg = glm(left ~ ., family=binomial(logit), data=datatot)
#controllo come sono distribuite le frequenze calcolate
hist(logreg$fitted.values)
#controllo che vi sia una buona correlazione, va abbastanza bene
cor(logreg$fitted.values,datatot$left)
#definisco un limite che mi dice se una probabilità va considerata come uno che se ne va o che rimane
cutoff=.5
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
#definisco un limite che mi dice se una probabilità va considerata come uno che se ne va o che rimane
cutoff=.3
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
res = matrix(ncol = 3)
#così vedo che 0.3 è un  buon valore, a me interessa tra l'altro tenere la gente, quindi allargo le maglie
res <- rbind(res,c(v,
for (v in seq(0,1, by=0.005)){
sum((logreg$fitted.values>v)&(datatot$left==1))/sum(datatot$left==1)
sum((logreg$fitted.values<=v)&(datatot$left==0))/sum(datatot$left==0),
}
))
plot(res[,1],res[,2])
plot(res[,1],res[,3])
#controllo il modello, in questo caso tutti i valori sembrano importanti (molti dati)
# z mi dice quanto sono importanti, quindi soddisfazione, Time in Company e #Projects
summary(logreg)
#provo a plottare ma ottengo un brutto diagramma, ho tante palle esattamente sovrapposte
plot(datatot$TIC,datatot$left,main= "Time and Employee Attrition", ylab="Attrition", xlab= "Time spent")
#rifaccio il plot usando al posto di si/no la percentuale di persone che ha mollato sul totale
tempdata=datatot
#raggruppo per il tempo in azienda e sopra faccio la media dei left (come split)
aggbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=mean)
#adesso posso graficare
plot(aggbTimeRank$TIC,aggbTimeRank$left,main= "Abbandono", ylab="Media abbandoni", xlab= "Tempo in azienda")
#se non se ne vanno dopo 5 anni poi rimangono
#posso migliorare mostrando il valore assoluto del numero di persone
#come sopra, ma qui conto il numero di persone
cntbTimeRank=aggregate(left~ TIC, data=tempdata, FUN=length)
#mostro il grafico
symbols(aggbTimeRank$TIC,aggbTimeRank$left,circles=cntbTimeRank$left, inches=.75, fg="white", bg="red",main= "Time and Employee Attrition", ylab="Average Attrition Rate", xlab= "Time spent")
View(datatot)
rm(list=ls(all=TRUE))
datatot=read.table('DATA_3.02_HR2.csv', header = T,sep=',')
summary(datatot)
#controllo come stanno i dati dell'abbandono
table(datatot$left)
table(datatot$left)/nrow(datatot)
hist(datatot$left)
#calcolo le correlazioni tra tutte le variabili per iniziare a darmi un'idea
#le correlazioni però sono analizzate in modo separato, senza capire come interagiscono tra di loro. (in verità il numero di progetti aiuta a non far lasciare)
#la soddisfazione è correlata negativamente, il numero di progetti leggermente positivo e il newborn un po' positivo
cor(datatot)
#qui uso un modello di regressione logica, ottengo una probabilità di abbandono
logreg = glm(left ~ ., family=binomial(logit), data=datatot)
hist(logreg$fitted.values)
#controllo come sono distribuite le frequenze calcolate
#controllo che vi sia una buona correlazione, va abbastanza bene
cor(logreg$fitted.values,datatot$left)
#definisco un limite che mi dice se una probabilità va considerata come uno che se ne va o che rimane
cutoff=.3
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
#definisco un limite che mi dice se una probabilità va considerata come uno che se ne va o che rimane
cutoff=.5
#calcolo le percentuali di successo per on e off, le vorrei entrambe alte
sum((logreg$fitted.values<=cutoff)&(datatot$left==0))/sum(datatot$left==0)
sum((logreg$fitted.values>cutoff)&(datatot$left==1))/sum(datatot$left==1)
#calcolo la percentuale di classificazione corretta (in base al cutoff, così posso tunarlo)
mean((logreg$fitted.values>cutoff)==(datatot$left==1))
sum((logreg$fitted.values<=cutoff)
)
sum((logreg$fitted.values<=cutoff))/sum(logreg$fitted.values)
sum((logreg$fitted.values<=cutoff))/length(logreg$fitted.values)
sum((logreg$fitted.values>cutoff))/length(logreg$fitted.values)
cor(data[,2],as.numeric(data[,6]))
rm(list=ls(all=TRUE))
data=read.table('DATA_3.01_CREDIT.csv',sep=',',header=TRUE)
#View(data)
summary(data)
#income in kdollari, rating (score, la variabile indipendente da predirre), numero cc, età, #anni di studio, gender, studente?, sposato?, etnia, debito medio sulla carta
hist(data$Rating)
#creo un istogramma per vedere come sono distribuiti i vari dati
hist(data$Balance)
tapply(data$Income,data$Ethnicity,mean) #gli africani guadagnano di più
##trovo delle relazioni tra le varie colonne, ma non mi serve molto (non ho capito bene come mai, in effetti la correlazione tra rating e income/balancing è alta come poi capirò alla fine)
hist(data$Income)
cor(data[,c(1:5,10)])
#creo un modello di regressione lineare tra la mia variabile cercata (Rating) e tutte le altre (.=*, se volevo indagarne una sola la specificavo, se più di una le unico con +)
linreg=lm(Rating~.,data=data)
linregSmall=lm(Rating~Income+Cards+Married,data=data)
#dal modello posso ottenere la previsione dei rate, li intabello per dare un'idea dell'accuratezza
compareTable <- matrix(ncol=2, nrow = 300, dimnames = list(c(1:300),c("Rate","CRate")))
compareTable[,2] <- linreg$fitted.values
#se la plotto ho la perfezione se ho una retta di 45°
#controllo che vi sia buona correlazione, ce l'ho, però questa ha dei limiti (con molti numeri riesco sempre a trovare un buon algoritmo che fitta)
cor(linreg$fitted.values,data$Rating)
#graficamente vedo che per numeri bassi non fitta bene
compareTable <- compareTable[ order(compareTable[,1]), ]
#controllo i dettagli del mio modello
summary(linreg)
#noto che income, student e balance sono quelli che pesano di più (me lo dicono gli asterischi)
#primo e terzo positivi, il secondo influenza in modo negativo
plot(data$Balance,data$Rating)
plot(data$Income,data$Rating)
plot(data$Student,data$Rating)
#Ora posso presentare le relazioni scoperte, nelle prime due si vede bene una correlazione lineare, la terza bo
cor(head(compareTable[,1],10),head(compareTable[,2],10))
summary(linregSmall)
#infatti:
plot(compareTable)
#qui cerco la correlazione tra tutti i dati numerici nella tabella, escludo quindi quelli anagrafici discreti
# la corr mi da indicazioni solo sulla forza e la direzione della correlazione
compareTable[,1] <- data$Rating
cor(data[,2],as.numeric(data[,6]))
cor(data[,2],as.numeric(data[,7]))
source('C:/TInvention/DataScience/Business-2-eventi/Credit.R', encoding = 'UTF-8')
View(compareTable)
linreg=lm(Rating~.,data=data)
summary(linreg<)
summary(linreg)
cor(data[,c(1:5,10)])
mean(data[data["Gender"]=='Female',2])
data[data["Gender"]=='Female',2]
data[data["Gender"]=='male',2]
data[data["Gender"]=='Male',2]
data[data[6]=='Male',2]
data[data[6]=='Feale',2]
data[data[6]=='Female',2]
data[data[6]!='Female',2]
data[data[6]=='Male ',2]
mean(data[data["Student"]=='No',2]) media più o meno simile, anzi più alta
mean(data[data["Student"]=='No',2])
mean(data[data["Student"]!='No',2])
