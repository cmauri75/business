x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
y
x
e
plot(y)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
y <- 1:10
x1 <- 1:10
x2 <- 1:10
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof()
x2 <- 1:100
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
x2 <- 10:1
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
summaryRprof()
hillbert <- function (n){ i<-1:n; 1/outer(i-1,i,"+")};x <- hillbert(1000);system.time(svd(x))
library(swirl)
swirl()
ls()
quit()
library(swirl)
swirl()
View(plants)
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20, 10)
LETTERS
sample(LETTERS)
flips <- sample(c(0,1),100,replace=TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(100, size = 1, prob = 0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(100,25)
rnorm(10, mean = 100, sd = 25)
rpois(5, mean = 10)
rpois(5, 10)
my_pois <-  replicate(100, rpois(5, 10))
my_pois
cm <- colMeans(my_pois)
hist(cm)
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date("1969-01-01")
unclass(d2)
t1 <-  Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time())
t2 <- as.POSIXlt(Sys.time())
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(t2)
weekdays(d1)
months(d1)
months(t1)
quarters(t2)
t3 <- "October 17, 1986 08:24"
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
data(cars)
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(dist ~ speed, cars)
plot(x = cars$dist, y = cars$speed)
plot(x = cars$dist, y = cars$speed, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab="Stopping Distance")
View(cars)
plot(cars, main = "My Plot")
plot(cars, main = "My Plot", sub="My Plot Subtitle")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col=2)
plot(Cars, xlimit=c(10,15))
plot(cars, xlimit=c(10,15))
plot(cars, xlim=c(10,15))
plot(cars, pch=2
)
data(mtcars)
mtcars
View(mtcars)
?boxplot
boxplot(mpg ~ cyl)
boxplot(mtcars.mpg ~ cyl)
boxplot(mtcars,mpg ~ cyl)
boxplot(formula = mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
setwd("~/")
setwd("C:/TInvention/DataScience/Working")
rm(list-ls(all-TRUE))
rm(list-ls(all~TRUE))
ls(all=TRUE)
rm(list=ls(all=TRUE))
data=read.table('DATA_2.01_SKU.csv', header = T,sep=',')
setwd("C:/TInvention/DataScience/Business-clustering")
('DATA_2.01_SKU.csv', header = T,sep=',')
data=read.table('DATA_2.01_SKU.csv', header = T,sep=',')
View(data)
str(data)
summary(data)
plot(data$CV, data$ADS, main = "SKU Example", ylab="Average Daily Sales", xlab= "Coefficient of Variation")
plot(data$CV, data$ADS, main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
abline(v=0.2, col = "red") # we can draw a vertical line by using the abline function and passing it the v argument
abline(h=4, col="red") # we can draw a horizontal line by using the abline function and passing it the h argument
text(0.15,9.7, "Horses", col = "red") # we can add some text to our plot by using the text() function, here to label the group "Horses"
text(0.65,9, "Wild Bulls", col = "red") # and group "Wild Bulls"
text(0.8,2, "Crickets", col = "red") # and group "Crickets"
testdata = scale(data)
View(data)
View(testdata)
avg(data$ADS)
mean(data$ADS)
sd(data$ADS)
?scale
1-5.62
1-5.61
4.61/4.22
4.61/4.211324
data$ADS-mean(data$ADS)
data$ADS-mean(data$ADS)/sd(data$ADS)
(data$ADS-mean(data$ADS))/sd(data$ADS)
(data-mean(data))/sd(data)
lapply(data[,1:2],mean)
lapply(data[,1:2],(data-mean)
)
lapply(data,mean))
lapply(data,mean)
data-lapply(data,mean)
(data-lapply(data,mean))/lapply(data,sd)
?dist
d = dist(testdata, method = "euclidean")
d
hcward = hclust(d, method="ward.D")
hcward
hcward = hclust(d, method="ward.D")
hcward
?hclust
plot(x, labels = NULL, hang = 0.1, check = TRUE,
axes = TRUE, frame.plot = FALSE, ann = TRUE,
main = "Cluster Dendrogram",
sub = NULL, xlab = NULL, ylab = "Height", ...)
plot(hcward, labels = NULL, hang = 0.1, check = TRUE,
axes = TRUE, frame.plot = FALSE, ann = TRUE,
main = "Cluster Dendrogram",
sub = NULL, xlab = NULL, ylab = "Height", ...)
plot(hcward, labels = NULL, hang = 0.1, check = TRUE,
axes = TRUE, frame.plot = FALSE, ann = TRUE,
main = "Cluster Dendrogram",
sub = NULL, xlab = NULL, ylab = "Height)
;
plot(hcward, labels = NULL, hang = 0.1, check = TRUE,
axes = TRUE, frame.plot = FALSE, ann = TRUE,
main = "Cluster Dendrogram",
sub = NULL, xlab = NULL, ylab = "Height)
plot(hcward)
cutree(hcward,k=3)
cutree(hcward,k=5)
cutree(hcward,k=6)
data$groups<-cutree(hcward,k=3)
plot(data$CV, data$ADS, main = "SKU Example", ylab="Average Daily Sales", xlab= "Coefficient of Variation")
plot(data)
install.packages("lattice") #
library(lattice)
xyplot(ADS~ CV,main = "After Clustering", type="p",group=groups,data=data,
;
col=c('blue','green','red'))
xyplot(ADS~ CV,main = "After Clustering", type="p",group=groups,data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red'))
)
data$groups<-cutree(hcward,k=6)
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red'))
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','yellow'))
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray'))
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown'))
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
data$groups<-cutree(hcward,k=3)
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
rm(list=ls(all=TRUE))
data=read.table('DATA_2.02_HR.csv', header = T,sep=',')
plot(data$CV, data$ADS, main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
plot(data$S, data$LPE, main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
stat(data)
stats(data)
str(data)
summary(data)
testdata = scale(data)
summary(testdata)
sd(data$S)
plot(testdata$S, testdata$LPE, main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
View(testdata)
plot(testdata$S, testdata$LPE)
plot(testdata.S, testdata$LPE)
plot(testdata[S], testdata$LPE)
plot(testdata["S"], testdata$LPE)
plot(testdata["S"], testdata["LPE"])
plot(testdata["S"], testdata["LPE"], xlim= -10)
plot(testdata["S"], testdata["LPE"], xlim= -10, min=10)
plot(testdata["S"], testdata["LPE"], xlim=0)
plot(testdata["S"], testdata["LPE"], xlim=-1000)
plot(testdata["S"], testdata["LPE"])
plot(testdata["S"], testdata["LPE"], main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
plot(testdata["S"])
testdata["S"]
testdata[S]
testdata$S
testdata[\]
testdata[1]
testdata[1,]
testdata[,1]
plot(testdata[,1], testdata[1,"LPE"], main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
plot(testdata[,1], testdata[1,2], main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
plot(testdata[,1], testdata[,2], main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
d = dist(testdata, method = "euclidean")
data$groups<-cutree(hcward,k=4)
hcward = hclust(d, method="ward.D")
data$groups<-cutree(hcward,k=6)
data$groups<-cutree(hcward,k=8)
library(lattice)
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
aggdata = aggregate(.~ groups, data=data, FUN=mean)
View(aggdata)
View(aggdata)
data$groups<-cutree(hcward,k=4)
aggdata = aggregate(.~ groups, data=data, FUN=mean)
proptemp=aggregate(S~ groups, data=data, FUN=length)
View(proptemp)
View(testdata)
View(proptemp)
aggregate(newborn~ groups, data=data, FUN=length)
aggregate(Newborn~ groups, data=data, FUN=length)
sum(proptemp$S)
order(aggdata$proportion,decreasing=T)
aggdata$proportion,decreasing=T)
aggdata$proportion,decreasing=T
aggdata$proportion
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
aggdata
testdatab=data[,1:5]
View(testdatab)
testdatab=testdata[,1:5]
View(testdata)
View(testdatab)
View(data)
testdatab=data[,1:5]
View(testdata)
View(data)
View(testdata)
testdatab=data[,1:5]
View(testdatab)
testdata2=testdata[,1:5]
d2 = dist(testdata2, method = "euclidean")
hcward2 = hclust(d2, method="ward.D")
data$groups2<-cutree(hcward2,k=4)
aggdatab = aggregate(.~ groups, data=data, FUN=mean)
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
View(aggdatab)
View(aggdata)
View(aggdatab)
aggdatab2 = aggregate(.~ groups, data=data, FUN=mean)
proptemp2 = aggregate(S~ groups, data=data, FUN=length)
aggdata2$proportion=(proptemp$S)/sum(proptemp$S)
aggdata2 = aggdata2[order(aggdata2$proportion,decreasing=T),]
View(aggdatab2)
testdata = scale(data[,1:5])
#calcolo la distanza tra i punti col metodo euclideo
d = dist(testdata, method = "euclidean")
hcward = hclust(d, method="ward.D")
#riduco i cluster a meno e aggiungo la colonna ai miei dati originali
#calcolo i cluster
data$groups<-cutree(hcward,k=4)
#aggrego i miei dati in una tabella, usando la media
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
aggdata = aggregate(.~ groups, data=data, FUN=mean)
#quindi ordino desc per tale valore
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
#
#newborn è 0 o 1 perchè binario, questo crea artefatti nel clustering
View(aggdata)
write.csv2(aggdata, "HRResults")
write.csv2(aggdata, "HRResults")
write.csv2(aggdata, "HRResults.csv")
rm(list=ls(all=TRUE))
data=read.table('DATA_2.03_Telco.csv', header = T,sep=',')
d = dist(testdata, method = "euclidean")
testdata = scale(data)
d = dist(testdata, method = "euclidean")
hcward = hclust(d, method="ward.D")
data$groups<-cutree(hcward,k=8)
aggdata = aggregate(.~ groups, data=data, FUN=mean)
View(aggdata)
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
#quindi ordino desc per tale valore
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
aggdata = aggregate(.~ groups, data=data, FUN=mean)
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
#quindi ordino desc per tale valore
proptemp=aggregate(Calls~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
palette(rainbow(12, s = 0.6, v = 0.75)) # Select the colors to use
stars(aggdata[,2:(ncol(data))], len = 0.6, key.loc = c(11, 6),xlim=c(2,12),main = "Segments", draw.segments = TRUE,nrow = 2, cex = .75,labels=aggdata$groups)
#svuoto l'ambiente
rm(list=ls(all=TRUE))
data=read.table('DATA_2.01_SKU.csv', header = T,sep=',')
plot(data$CV, data$ADS, main = "SKU Example", ylab="Vendite medie", xlab= "Coefficente di varianza")
#questa funzione effettua lo scaling dei dati per renderli comparabili tra loro
statistic(data)
summary(data)
##posso replicarla con (data-lapply(data,mean))/lapply(data,sd) in pratica ad ogni valore tolgo la media della sua colonna e divido per la varianza della sua colonna
testdata = scale(data)
#calcolo la distanza tra i punti col metodo euclideo
d = dist(testdata, method = "euclidean")
#calcolo i cluster
hcward = hclust(d, method="ward.D")
data$groups<-cutree(hcward,k=2)
library(lattice)
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
rm(list=ls(all=TRUE))
#svuoto l'ambiente
#statisfation, evaluation, project worked, numero ore lavorate, tempo in azienda, nuovo bimbo negli ultimi 12 mesi
data=read.table('DATA_2.02_HR.csv', header = T,sep=',')
#rimuovo newborn dall'analisi perchè binario, questo crea artefatti nel clustering
testdata = scale(data[,1:5])
#calcolo la distanza tra i punti col metodo euclideo
d = dist(testdata, method = "euclidean")
#calcolo i cluster
d = dist(testdata, method = "euclidean")
#calcolo i cluster
hcward = hclust(d, method="ward.D")
#riduco i cluster a 3 e aggiungo la colonna ai miei dati originali
data$groups<-cutree(hcward,k=3)
library(lattice)
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
xyplot(LPE~ NP, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
xyplot(NP~ LPE, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))
rm(list=ls(all=TRUE))
#statisfation, evaluation, project worked, numero ore lavorate, tempo in azienda, nuovo bimbo negli ultimi 12 mesi
data=read.table('DATA_2.02_HR.csv', header = T,sep=',')
xyplot(ADS~ CV, main = "Grafico colorato coi cluster", type="p", group=groups, data=data, auto.key=list(title="Group", space = "left", cex=1.0, just = 0.95), par.settings = list(superpose.line=list(pch = 0:18, cex=1)), col=c('blue','green','red','gray','brown','black'))data
head(data)
testdata = scale(data[,1:3])
testdata
head(testdata)
d = dist(testdata, method = "euclidean")
#calcolo i cluster
hcward = hclust(d, method="ward.D")
data$groups<-cutree(hcward,k=2)
#aggrego i miei dati in una tabella, usando la media
aggdata = aggregate(.~ groups, data=data, FUN=mean)
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
#quindi ordino desc per tale valore
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
aggdata
aggdata[S]
aggdata[,"S"]
aggdata["S"]
round(aggdata["S"])
round(aggdata["S"],3)
round(aggdata["S"],2)
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_2.03_Telco.csv', header = T,sep=',')# The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
# Now let's normalize our variables
testdata=data # To keep our dataset safe, let's create a copy of it called "testdata"
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
testdata = scale(testdata) # the scale function automatically performs data normalization on all your variables
hcward = hclust(d, method="ward.D") # hclust() function performs hiearchical clustering, we pass it the distances, and we set the method argument to "ward.D"
aggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values
data$groups=cutree(hcward,k=8) # assign our points to our k=8 clusters
d = dist(testdata, method = "euclidean") # the dist() function computes the distances of all the observations in our dataset
proptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group
aggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group
# Let's try again with 5 segments
data$groups= cutree(hcward,k=5) #Create segments for k=5
aggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest
#write.csv(aggdata, file = "aggdataTelco5seg.csv", row.names=FALSE) # Let's save the output in a csv to work on it in Excel later
aggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values
# Let's draw the radar chart with the function stars()
palette(rainbow(12, s = 0.6, v = 0.75)) # Select the colors to use
proptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group
stars(aggdata[,2:(ncol(data))], len = 0.6, key.loc = c(11, 6),xlim=c(2,12),main = "Segments", draw.segments = TRUE,nrow = 2, cex = .75,labels=aggdata$groups)
rm(list=ls(all=TRUE))
# Let's load the data
data=read.table('DATA_2.03_Telco.csv', header = T,sep=',')# The function read.table enables us to read flat files such as .csv files
# Now let's have a look at our variables and see some summary statistics
str(data) # The str() function shows the structure of your dataset and details the type of variables that it contains
summary(data) # The summary() function provides for each variable in your dataset the minimum, mean, maximum and quartiles
# Now let's normalize our variables
testdata=data # To keep our dataset safe, let's create a copy of it called "testdata"
testdata = scale(testdata) # the scale function automatically performs data normalization on all your variables
d = dist(testdata, method = "euclidean") # the dist() function computes the distances of all the observations in our dataset
hcward = hclust(d, method="ward.D") # hclust() function performs hiearchical clustering, we pass it the distances, and we set the method argument to "ward.D"
data$groups=cutree(hcward,k=8) # assign our points to our k=8 clusters
aggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values
proptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group
aggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest
# Let's try again with 5 segments
data$groups= cutree(hcward,k=5) #Create segments for k=5
aggdata= aggregate(.~ groups, data=data, FUN=mean) # Aggregation by group and computation of the mean values
proptemp=aggregate(Calls~ groups, data=data, FUN=length) # Computation of the number of observations by group
aggdata$proportion=(proptemp$Calls)/sum(proptemp$Calls) # Computation of the proportion by group
aggdata=aggdata[order(aggdata$proportion,decreasing=T),] # Ordering from the largest group to the smallest
aggdata
View(aggdata)
#write.csv(aggdata, file = "aggdataTelco5seg.csv", row.names=FALSE) # Let's save the output in a csv to work on it in Excel later
# Let's draw the radar chart with the function stars()
palette(rainbow(12, s = 0.6, v = 0.75)) # Select the colors to use
stars(aggdata[,2:(ncol(data))], len = 0.6, key.loc = c(11, 6),xlim=c(2,12),main = "Segments", draw.segments = TRUE,nrow = 2, cex = .75,labels=aggdata$groups)
round(aggdata,2)
rm(list=ls(all=TRUE))
#statisfation, evaluation, project worked, numero ore lavorate, tempo in azienda, nuovo bimbo negli ultimi 12 mesi
data=read.table('DATA_2.02_HR.csv', header = T,sep=',')
#rimuovo newborn dall'analisi perchè binario, questo crea artefatti nel clustering
testdata = scale(data[,1:3])
#calcolo la distanza tra i punti col metodo euclideo
d = dist(testdata, method = "euclidean")
#calcolo i cluster
hcward = hclust(d, method="ward.D")
data$groups<-cutree(hcward,k=2)
#aggrego i miei dati in una tabella, usando la media
#aggrego i miei dati in una tabella, usando la media
aggdata = aggregate(.~ groups, data=data, FUN=mean)
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
View(testdata)
View(data)
#quindi ordino desc per tale valore
proptemp=aggregate(S~ groups, data=data, FUN=length)
View(proptemp)
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
summary(data)
aggdata = aggregate(.~ groups, data=data, FUN=median)
#conto il numero di valori in ogni gruppo, posso usare una colonna qualsiasi
#ne faccio la percentuale e la aggiungo come colonna ai dati
#quindi ordino desc per tale valore
proptemp=aggregate(S~ groups, data=data, FUN=length)
aggdata$proportion=(proptemp$S)/sum(proptemp$S)
aggdata=aggdata[order(aggdata$proportion,decreasing=T),]
?lm
